{"componentChunkName":"component---src-templates-blog-post-js","path":"/big-o-factorial-time-complexity/","result":{"data":{"site":{"siteMetadata":{"title":"jarednielsen.com","author":"Jared Nielsen"}},"markdownRemark":{"id":"b473935e-9bce-5862-963d-ce2c7117bc1a","excerpt":"Is there a computer science topic more terrifying than Big O notation? Don‚Äôt let the name scare you, Big O notation is not a big deal. It‚Äôs very easy to‚Ä¶","html":"<p>\n  <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/36abe77b998054914b2d38002d33cace/2f950/jarednielsen-big-o-factorial-time-complexity.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n  \n  <span\n    class=\"gatsby-resp-image-wrapper\"\n    style=\"position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;\"\n  >\n    <span\n      class=\"gatsby-resp-image-background-image\"\n      style=\"padding-bottom: 56.25%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAABO0lEQVQoz62Sy0vEMBDG+/9fRfEmLCh78gEqiAiriNIV3BVRlEVED4uo+Oi2TfP8TCaJ25bqRQMDX5KZ30wykxhj0DCtYQAYpWmPqJXyd3WfqGvxSRtIACEDyEJKhrgaPkUJI5UH6y6gDXaLD1IUy33olzerh5BXE+iPDOL82t8fnkFnOdTNHVh/Z564AYxl24z5Qg/idATW20S1PYDhAtXuEcqVdajHKfjeMdT0mUDl4irBCRoYSf3v3GIb+yiW1iDSMaqtA5i8gBhegp+MICcPvuL3DBDCA+3Tu4Hxb2yV+umVtEgvoG7v/XnFfVD4U/dkV233kx3MOUtpGyKst2+GYQz6c2ZhFWkyzsn0LPfaNpCa4+KtJZ1jE0ckZqaxCRYCv89p/9PYuPLjiLQ0WufzOPw+h3+1fwd+AYt9WRll+f1ZAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n    >\n      <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\"\n        alt=\"jarednielsen big o factorial time complexity\"\n        title=\"\"\n        src=\"/static/36abe77b998054914b2d38002d33cace/b9e4f/jarednielsen-big-o-factorial-time-complexity.png\"\n        srcset=\"/static/36abe77b998054914b2d38002d33cace/cf440/jarednielsen-big-o-factorial-time-complexity.png 148w,\n/static/36abe77b998054914b2d38002d33cace/d2d38/jarednielsen-big-o-factorial-time-complexity.png 295w,\n/static/36abe77b998054914b2d38002d33cace/b9e4f/jarednielsen-big-o-factorial-time-complexity.png 590w,\n/static/36abe77b998054914b2d38002d33cace/f9b6a/jarednielsen-big-o-factorial-time-complexity.png 885w,\n/static/36abe77b998054914b2d38002d33cace/2d849/jarednielsen-big-o-factorial-time-complexity.png 1180w,\n/static/36abe77b998054914b2d38002d33cace/2f950/jarednielsen-big-o-factorial-time-complexity.png 1600w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n      />\n    </span>\n  </span>\n  \n  </a>\n    </p>\n<p>Is there a computer science topic more terrifying than Big O notation? Don‚Äôt let the name scare you, Big O notation is not a big deal. It‚Äôs very easy to understand and you don‚Äôt need to be a math whiz to do so. In this tutorial, you‚Äôll learn the fundamentals of Big O factorial time complexity.</p>\n<h2>What Problem(s) Does Big O Notation Solve?</h2>\n<ul>\n<li>Big O notation helps us answer the question, ‚ÄúWill it scale?‚Äù </li>\n<li>Big O notation equips us with a shared language for discussing performance with other developers (and mathematicians!).</li>\n</ul>\n<h2>Quick Refresher</h2>\n<p>This is the last article in a series on Big O notation. If you‚Äôre just joining us, you may want to start at the beginning with <a href=\"https://jarednielsen.com/big-o-notation/\">What is Big O Notation?</a>.</p>\n<h3>What is Big O Notation?</h3>\n<p>Big O notation is a system for measuring the rate of growth of an algorithm. Big O notation mathematically describes the complexity of an algorithm in terms of time and space. We don‚Äôt measure the <em>speed</em> of an algorithm in seconds (or minutes!). Instead, we measure the number of operations it takes to complete. </p>\n<p>The O is short for ‚ÄúOrder of‚Äù. So, if we‚Äôre discussing an algorithm with <em>O(n)</em>, we say its <em>order of</em>, or rate of growth, is <em>n</em>, or linear complexity. </p>\n<h3>How Does Big O Notation Work?</h3>\n<p>Big O notation measures the <em>worst-case runtime</em>. </p>\n<p>Why?</p>\n<p>Because we don‚Äôt know what we don‚Äôt know.</p>\n<p>We need to know just how poorly our algorithm will perform so we can compare it to other solutions. </p>\n<p>The worst-case scenario is also known as the ‚Äúupper bound‚Äù. </p>\n<p>Remember this table? </p>\n<table>\n<thead>\n<tr>\n<th>O</th>\n<th>Complexity</th>\n<th>Rate of growth</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>O(1)</td>\n<td>constant</td>\n<td>fast</td>\n</tr>\n<tr>\n<td>O(log n)</td>\n<td>logarithmic</td>\n<td></td>\n</tr>\n<tr>\n<td>O(n)</td>\n<td>linear</td>\n<td></td>\n</tr>\n<tr>\n<td>O(n * log n)</td>\n<td>log linear</td>\n<td></td>\n</tr>\n<tr>\n<td>O(n^2)</td>\n<td>quadratic</td>\n<td></td>\n</tr>\n<tr>\n<td>O(n^3)</td>\n<td>cubic</td>\n<td></td>\n</tr>\n<tr>\n<td>O(2^n)</td>\n<td>exponential</td>\n<td></td>\n</tr>\n<tr>\n<td>O(n!)</td>\n<td>factorial</td>\n<td>slow</td>\n</tr>\n</tbody>\n</table>\n<p>It lists common orders from fastest to slowest. </p>\n<h2>Big O Factorial Time Complexity</h2>\n<p>Here we are, at the end of our journey. </p>\n<p>And we saved the worst for last.</p>\n<p>O(n!)</p>\n<p>AKA factorial time complexity.</p>\n<p>If Big O helps us identify the worst-case scenario for our algorithms, O(n!) is the worst of the worst. </p>\n<p>Why? </p>\n<p>Recall that a factorial is the product of the sequence of <em>n</em> integers. </p>\n<p>For example, the factorial of 5, or <em>5!</em>, is:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">5 * 4 * 3 * 2 * 1 = 120</code></pre></div>\n<p>We will find ourselves writing algorithms with factorial time complexity when calculating permutations and combinations.</p>\n<p>If we look at our chart, we see that our rate of growth is nearly vertical. </p>\n<p>\n  <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/9c24f10d0295ead7526e32d62fa2eac5/4117f/big-o-cheatsheet.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n  \n  <span\n    class=\"gatsby-resp-image-wrapper\"\n    style=\"position: relative; display: block;  max-width: 590px; margin-left: auto; margin-right: auto;\"\n  >\n    <span\n      class=\"gatsby-resp-image-background-image\"\n      style=\"padding-bottom: 63.15359477124183%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAIAAAAmMtkJAAAACXBIWXMAAAsSAAALEgHS3X78AAACrUlEQVQoz1XRSUwTYRQH8I94Mh7UgyeN8WJijCfjtXZaynYQIXoyeDHRRG/GoMZAHDpMZyEIGBXFgxcTJVIENMFSkO5lWmQ1sQudQikpUFlmulra7zkDhITkHf75kl/ee99DpUIhHw5nAoFcKASRCI5Gc4HARs/7jdddG8ONCf8dYexe99B1i60ZojEsRkAU1QovQUxE2WQySZLRxsZkczNmmCxFrTU1ZRkG2tuB7wCuC/guaHsJXAcoj6wJaA7oNuh+CGO3UGZ9XTaZZKOxyHHA85ISWBaUzLJYDQxmd4tTpMLaoZOEgdvg0YL/moolmt4myT2Toii8hw8VqzIlfHwAjmqYIMCtB6EeZZJJmaYlksQct8MwyghKf3zAeBaYNlW+ewKWeuwlsKccPJVFpy7rqEXxYDBlMm3v4hxN52lawfuM5aH1BXS2wEADeHUg6HbshsTQ1dXvWmlEk3fWonlBSDHMHpYPFuYPzykQ4DHsOAypUd2WhciN67FbB746FJiaUrDU0pI3mZSFgef253z7GKx14Ndir/6frVy2EkoV7HrwGmDCAG4ChDp1502KShmN6VYqTyuX6FD/c7BBGbLo1WZ/EpJVmx4jik51VXBVgrMK7DUwXoXdN9Q7/6WMm+TzNMngNhY+3S85KvIujTyil36UZ0crSrZqcNSobEIPfg3MX4GFixA/A1vnVbzZyqw9I0s9T7HlZt6uV0DBZlA6w4wGQpchdgGSZ0E+BeljUDwCgADKMEZb0gkkJ9YmH90NvjLEhy/FbOcSvtOJuZPxwNHFSJm4giKr6E8CzcbRdAz9WkKCiLwiGp0vGxTQN/9xlMvkAlNWcaE/HOlbWPwSWOwNxT+HVnpDK/22yTdfraxr7sPv2MB0tH922TyzbJ5eNvuiZlewzycO/QeV1h5qGVp6JgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n    >\n      <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\"\n        alt=\"big o cheatsheet\"\n        title=\"\"\n        src=\"/static/9c24f10d0295ead7526e32d62fa2eac5/b9e4f/big-o-cheatsheet.png\"\n        srcset=\"/static/9c24f10d0295ead7526e32d62fa2eac5/cf440/big-o-cheatsheet.png 148w,\n/static/9c24f10d0295ead7526e32d62fa2eac5/d2d38/big-o-cheatsheet.png 295w,\n/static/9c24f10d0295ead7526e32d62fa2eac5/b9e4f/big-o-cheatsheet.png 590w,\n/static/9c24f10d0295ead7526e32d62fa2eac5/f9b6a/big-o-cheatsheet.png 885w,\n/static/9c24f10d0295ead7526e32d62fa2eac5/2d849/big-o-cheatsheet.png 1180w,\n/static/9c24f10d0295ead7526e32d62fa2eac5/4117f/big-o-cheatsheet.png 2448w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n      />\n    </span>\n  </span>\n  \n  </a>\n    </p>\n<p>That‚Äôs great if we‚Äôre going to the Moon, but not if we are writing algorithms. </p>\n<p>üöÄüååüåô</p>\n<p>Why would anyone ever write an algorithm with factorial time complexity? </p>\n<p>It‚Äôs not that we <em>want</em> to write terrible algorithms. </p>\n<p>The problem is the problems. </p>\n<p>There are some problems for which there is no easy solution. </p>\n<h2>NP-Complete Problems</h2>\n<p>These are what are known as <em>NP-complete</em> problems. </p>\n<p>NP-complete is a concept in complexity theory used to describe a category of problems for which there is no known correct <em>and</em> fast solution.</p>\n<p>In other words, the solution to an NP-complete problem can be quickly verified, but there is no known way to quickly find a solution. </p>\n<p>It‚Äôs important to distinguish between two types of <em>solution</em>. </p>\n<p>There‚Äôs the solution as <em>algorithm</em>, i.e: the function that we can apply to any input to solve this problem. </p>\n<p>And there‚Äôs the solution as <em>output</em>, i.e: the specific value we want our function to return.</p>\n<p>With NP-complete problems, we can prove our solution, as algorithm, will work on a small input, but the time to find a specific solution, as output, grows rapidly as the input size increases.</p>\n<p>Complexity theory is a big topic and deserves a series of its own, so we‚Äôll leave it at that.</p>\n<p>Let‚Äôs look at a few ‚Äòreal-world‚Äô examples that may help illustrate this concept. </p>\n<h3>The Traveling Salesman</h3>\n<p>A classic example of NP-complete is the <a href=\"https://en.wikipedia.org/wiki/Travelling_salesman_problem\">Traveling Salesman Problem</a>.</p>\n<p>AKA TSP.</p>\n<p>Say you‚Äôre a traveling salesperson and you need to visit <em>n</em> cities. What is the shortest route that visits each and returns you to your start? </p>\n<p>To solve this, we need to calculate every possible route. </p>\n<p>Let‚Äôs start with 3 cities: Austin, Boston and Chicago</p>\n<p>How many permutations are there? </p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Austin &gt; Boston &gt; Chicago\nAustin &gt; Chicago &gt; Boston\nBoston &gt; Austin &gt; Chicago\nBoston &gt; Chicago &gt; Austin\nChicago &gt; Austin &gt; Boston\nChicago &gt; Boston &gt; Austin</code></pre></div>\n<p>This is <em>3!</em>, which is six permutations.</p>\n<p>Why? </p>\n<p>If we have three possible starting points, then for each starting point we have two possible routes to the final destination.</p>\n<p>What if we need to visit 4 cities? Austin, Boston, Chicago, and Detroit.</p>\n<p>How many permutations? </p>\n<p>That would be <em>4!</em>, which is 24 permutations.</p>\n<p>Why? </p>\n<p>If we have four possible starting points, then for each starting point we have three possible routes, and for each of those points, we have two possible routes, and the final stop. So:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">4 * 3 * 2 * 1</code></pre></div>\n<p>And five?</p>\n<p>As we saw above, that‚Äôs 120. </p>\n<p>What about 10? </p>\n<p>Uh oh.</p>\n<p>(Or should I say, <code>Uh O</code>?)</p>\n<p>That‚Äôs 3628800. </p>\n<p>That‚Äôs a big increase and a lot of computational processing.</p>\n<p>We could easily write an algorithm to brute force a solution for small inputs, but it doesn‚Äôt take long before we cross a threshold requiring us to make millions (and more!) calculations. </p>\n<h3>The Knapsack Problem</h3>\n<p>The <a href=\"https://en.wikipedia.org/wiki/Knapsack_problem\">Knapsack Problem</a> is another classic NP-complete problem. </p>\n<p>It‚Äôs a resource allocation problem in which we are trying to find an optimized combination under a set of constraints. </p>\n<p>Say you‚Äôve got an inventory of flat panel TVs from multiple manufacturers and you need to fill a shipping container with them. Larger TVs are worth more, but they also take up more space. You want to pack as many TVs into the container as possible to maximize your profit. </p>\n<p>How do we solve this problem? </p>\n<p>The brute force approach is to calculate all possible combinations and select the ‚Äúbest‚Äù which takes us into the realm of factorial time complexity.</p>\n<p>Lucky for us, there are several solutions using <a href=\"https://jarednielsen.com/dynamic-programming-memoization-tabulation/\">dynamic programming</a> that are more elegant and (slightly more) efficient.</p>\n<h3>The Clique Problem</h3>\n<p>The <a href=\"https://en.wikipedia.org/wiki/Clique_problem\">Clique Problem</a> asks us to find all subsets of vertices in a graph. </p>\n<p>It might be easier to think of this as the ‚ÄúSocial Network Problem‚Äù or ‚ÄúThe One Degree of Kevin Bacon Problem‚Äù: given a network of individuals, how do you find the closest friends for each of them?</p>\n<h2>How Do We Solve NP-Complete Problems?</h2>\n<p>We know we can solve NP-complete problems. </p>\n<p>The problem is we don‚Äôt have time.</p>\n<p>The solution is <em>heuristics</em>. </p>\n<p>In computer science, a <a href=\"https://en.wikipedia.org/wiki/Heuristic_(computer_science)\">heuristic algorithm</a> is an approach for finding an approximate, or ‚Äògood enough‚Äô solution. </p>\n<p>You are reading this book because you are a practitioner, not an academic. </p>\n<p>Academics get paid to create problems. </p>\n<p>We get paid to solve them. </p>\n<p>A parting quote, generally attributed to Sheryl Sandberg:</p>\n<blockquote>\n<p>Done is better than perfect. </p>\n</blockquote>\n<p>Just like this article. </p>\n<h2>Big O Factorial Time Complexity</h2>\n<p>Big O notation is not a big deal. It‚Äôs very easy to understand and you don‚Äôt need to be a math whiz to do so. In this tutorial, you learned the fundamentals of Big O factorial time complexity. Now go solve problems! Just don‚Äôt waste your time on the hard ones. </p>","frontmatter":{"title":"Big O Factorial Time Complexity","date":"April 17, 2020","description":"Big O notation is not a big deal. Learn the fundamentals of Big O factorial time complexity."}}},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"/big-o-factorial-time-complexity/","previous":{"fields":{"slug":"/analogy-learning-software-development/"},"frontmatter":{"title":"Analogy in Learning and Software Development"}},"next":null}}}